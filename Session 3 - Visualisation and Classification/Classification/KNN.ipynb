{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN is a simple classification algorithm. It classifies cases based on a similarity measure relying on the labels belonging to the K nearest points in the training set. In that sense, it is actually quite easy to code yourself. In this notebook, we will take you through a set of functions that calculate the neirest neighbours, but will also show you how to do it with Scikit-Learn. Let's start with importing the required libraries for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import neighbors as neigh\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import feature_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define all the functions we need to implement KNN classification algorithm. Don't worry if these functions seem a bit complex to you in terms of code, we won't ask you to replicate it, it's just for showing you step by step how the KNN algorithm works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by calculating the distance between two data instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Euclidean Distance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def euclideanDistance(instance1, instance2):\n",
    "    length = len(instance1)\n",
    "    # you can also check if instance1 and instance2 have the same length\n",
    "    distance = 0\n",
    "    for l in range(length):\n",
    "        distance += (instance1[l] - instance2[l])**2\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = [0,1,2]\n",
    "data2 = [0,2,4]\n",
    "distance = euclideanDistance(data1, data2)\n",
    "print ('Distance: ', distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to get the K nearest neighbors of a point in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getNeighbors(data, labels, testInstance, K):\n",
    "    distances = []\n",
    "    neighbors = {}\n",
    "    #Finds the distances between all the points and creates a list of tuples.\n",
    "    for i in range(len(data)):\n",
    "        dist = euclideanDistance(testInstance, data[i, :])\n",
    "        distances.append([data[i,:], dist])\n",
    "\n",
    "    #Sorts the list of distances by using the second element of the tuple, i.e. the distance    \n",
    "\n",
    "    idx = np.argsort(np.array(distances)[:, 1])\n",
    "    neighbors_data = data[idx]\n",
    "    neighbors_label = labels[idx]\n",
    "    \n",
    "    neighbors =  {'data': neighbors_data[:K], 'labels': neighbors_label[:K]}\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the training set: 2 points and 2 labels\n",
    "data = np.array([[2, 2, 2], [4, 4, 4]])\n",
    "labels = np.array([0, 1])\n",
    "\n",
    "# define the test instance\n",
    "testInstance = [5, 5, 5]\n",
    "\n",
    "# choose the number of neighbours\n",
    "K = 1\n",
    "\n",
    "# find & retrieve the K nearest points to the test instance, sorted by the distance\n",
    "neighbors = getNeighbors(data, labels, testInstance, K)\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a Response function: this counts the number of times a certain class appears in the set of neighbours that we've found with the previous function. The class with the highest frequency will be the label assigned to the test instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    #Assign the votes for every class\n",
    "    for i in range(len(neighbors)):\n",
    "        response = neighbors[i]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    \n",
    "    #Use the dictionary to short which class has the most votes\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #print sortedVotes\n",
    "    return sortedVotes[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# in this case we have two 1s and one 0: class 1 wins.\n",
    "neighbors['labels'] = np.array([1, 1, 0])\n",
    "response = getResponse(neighbors['labels'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the accuracy of our model: This should be a familiar concept by now, it is a way to test the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        #If the label of the testSet and the prediction are the same add one.\n",
    "        if testSet[i] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (float(correct)/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# true labels\n",
    "testSet = np.array(['a','a','b'])\n",
    "\n",
    "# predicted labels\n",
    "predictions = ['a', 'a', 'a']\n",
    "\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** <br> Assign a label to the test instance, basing on the following training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = np.array([[1, 1, 1], [1, 3, 5], [7, 5, 4], [9, 5, 3]])\n",
    "training_labels = np.array([1, 2, 1, 2])\n",
    "test_instance = np.array([4, 4, 4])\n",
    "\n",
    "# get K neighbours\n",
    "K = #TYPEHERE\n",
    "neighbours = #TYPEHERE\n",
    "\n",
    "# get the label\n",
    "label = #TYPEHERE\n",
    "\n",
    "print label\n",
    "\n",
    "# what about the accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now, with real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have all the tools we need to classify data. Now we want to test the algorithm over real data. For that we will use a dataset containing information on wines. What our algorithm can is do is to predict the origin of the wine, by its chemical characteristics. For all you Oenophiles (https://en.wikipedia.org/wiki/Oenophilia) out there: who wouldn't love a wine classifier tool, right!? \n",
    "\n",
    "The data is the result of chemical analysis of wines grown in the same region in Tuscany, Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. \n",
    "\n",
    "Our data consists of the following features and classes:\n",
    "\n",
    "The attributes are: \n",
    "\n",
    "1. Alcohol \n",
    "2. Malic acid \n",
    "3. Ash \n",
    "4. Alcalinity of ash \n",
    "5. Magnesium \n",
    "6. Total phenols \n",
    "7. Flavanoids \n",
    "8. Nonflavanoid phenols \n",
    "9. Proanthocyanins \n",
    "10. Color intensity \n",
    "11. Hue \n",
    "12. OD280/OD315 of diluted wines \n",
    "13. Proline \n",
    "\n",
    "The classes are given under the variables \"Class\" and \"Origin\" and are respectively:\n",
    "\n",
    "1. from Siena \n",
    "2. from Lucca\n",
    "3. from Pisa\n",
    "\n",
    "Cheers!\n",
    "\n",
    "\n",
    "![alt text](wines.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('wine_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at how our classes are divived. This is always important to do in classifications problems. We would ideally like each of our classes to be quite equal in size, otherwise we would have to address a problem of unbalanced classes. So let's create a bar chart of our classes, we'll take the variable 'Origin' but we could do the same with 'Class', as they're just the numeric and string representation of our classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wineorigin=pd.DataFrame(data['Origin'].value_counts())\n",
    "plt.figure()\n",
    "wineorigin.plot(kind='bar')\n",
    "plt.xlabel('Origin of wine')\n",
    "plt.ylabel('Number of instances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So...Do you think these classes are unbalanced?\n",
    "\n",
    "Now to test the algorithm, we first need to split the data into training and test set, and convert the parts to Numpy array, just like we've done before. We can use \"Class\" for train_Y and the rest of the variables, without \"Origin\" for train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, train_size = 0.7)\n",
    "\n",
    "train_X = np.array(train)[:, 2:].astype(float)\n",
    "train_Y = np.array(train)[:,0].astype(float)\n",
    "\n",
    "test_X = np.array(test)[:, 2:].astype(float)\n",
    "test_Y = np.array(test)[:,0].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that our data is split into train and test data, let's rerun our own defined 1 - NN algorithm on our data, using the functions we created earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "K = 1\n",
    "for i in range(len(test_Y)):\n",
    "    neighbors = getNeighbors(train_X, train_Y, test_X[i,:], K)\n",
    "    result = getResponse(neighbors['labels'])\n",
    "    predictions.append(result)\n",
    "accuracy = getAccuracy(test_Y, predictions)\n",
    "print ('Accuracy: ', accuracy, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to make things easier, we can actually also use the sklearn library, let's see what this does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = neigh.KNeighborsClassifier(K)\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "predictions1 = clf.predict(test_X)\n",
    "\n",
    "accuracy = getAccuracy(test_Y, predictions1)\n",
    "print('Accuracy: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a look at the values in the data, we can see that they have different orders of magnitude for different features. Let's work our feature scaling magic and do a short exercise to scale our train_X set to make the different features better aligned.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** <br> Can you scale the train_X feature set using the mean and standard deviation for train_X and this relation: \n",
    "\n",
    "$$ScaledX = \\frac{X - mean}{std}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute mean and standard deviation of training set\n",
    "mean = # TYPE HERE use numpy\n",
    "std = # TYPE HERE \n",
    "\n",
    "#Hint, you might want to use the option \"axis=0\" when you calculate mean and std, as you want to tell python to calculate your numbers over columns, not over rows\n",
    "\n",
    "# now scale test set using the mean and std of the training set\n",
    "train_Xscaled = # TYPE HERE \n",
    "test_Xscaled = # TYPE HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = 1\n",
    "clf = neigh.KNeighborsClassifier(K)\n",
    "clf.fit(train_Xscaled, train_Y)\n",
    "\n",
    "predictions = clf.predict(test_Xscaled)\n",
    "\n",
    "accuracy = getAccuracy(test_Y, predictions)\n",
    "print('Accuracy: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also investigate other metrics, such as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(test_Y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try setting weights (i.e. using the distance of neighbours to weigh their relative importance), and see if our performance increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = 1\n",
    "clf = neigh.KNeighborsClassifier(K, weights='distance')\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "predictions = clf.predict(test_X)\n",
    "\n",
    "# accuracy = getAccuracy(test_Y, predictions)\n",
    "accuracy = sklearn.metrics.accuracy_score(test_Y, predictions)*100\n",
    "print('Accuracy: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we increase the  number of neighbours taken into account? We can plot the accuracy accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotvector(train_X, train_Y, test_X, test_Y, weights, upperLim = 100):\n",
    "    results = []\n",
    "    for k in range(1, upperLim, 4):\n",
    "        clf = neigh.KNeighborsClassifier(n_neighbors = k, weights = weights)\n",
    "        clf = clf.fit(train_X, train_Y)\n",
    "        preds = clf.predict(test_X)\n",
    "        accuracy = clf.score(test_X, test_Y)\n",
    "        results.append([k, accuracy*100])\n",
    " \n",
    "    results = np.array(results)\n",
    "    return(results)\n",
    "\n",
    "pltvector1 = plotvector(train_X, train_Y, test_X, test_Y, weights = \"uniform\")\n",
    "pltvector2 = plotvector(train_X, train_Y, test_X, test_Y,  weights = \"distance\")\n",
    "line1 = plt.plot(pltvector1[:,0], pltvector1[:,1], label = \"uniform\")\n",
    "line2 = plt.plot(pltvector2[:,0], pltvector2[:,1], label = \"distance\")\n",
    "plt.legend(loc=3)\n",
    "plt.ylim(60, 80)\n",
    "plt.title(\"Accuracy with Increasing K\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do a step of feature selection, in order to maintain only the most descriptive features. More specifically, the sklearn.feature_selection module can be used for feature selection/dimensionality reduction on sample sets, either to improve estimators’ accuracy scores or to boost their performance on very high-dimensional datasets. Univariate feature selection works by selecting the best features based on univariate statistical tests.\n",
    "\n",
    "First, we select the optimal number of features, through cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percentiles = range(1, 100, 5)\n",
    "results = []\n",
    "for i in range(1, 100, 5):\n",
    "    fs = feature_selection.SelectPercentile(sklearn.feature_selection.f_classif, percentile=i)\n",
    "    X_train_fs = fs.fit_transform(train_Xscaled, train_Y)\n",
    "    scores = cross_val_score(clf, X_train_fs, train_Y, cv=5)\n",
    "    results = np.append(results, scores.mean())\n",
    "\n",
    "optimal_percentil = np.where(results == results.max())[0]\n",
    "if len(optimal_percentil)>1:\n",
    "    optimal_percentil=optimal_percentil[0]\n",
    "#print (\"Optimal percentil :{0}\",format(percentiles[optimal_percentil]), \"\\n\")\n",
    "\n",
    "print (\"Optimal percentil:\",optimal_percentil)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "import pylab as pl\n",
    "pl.figure()\n",
    "pl.xlabel(\"Number of features selected\")\n",
    "pl.ylabel(\"Cross validation accuracy)\")\n",
    "pl.plot(percentiles,results)\n",
    "print (\"Mean scores:\",results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we select the relevant features and we repeat the KNN algorithm with the transformed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = sklearn.feature_selection.SelectPercentile(sklearn.feature_selection.f_classif, percentile=percentiles[optimal_percentil])\n",
    "X_train_fs = fs.fit_transform(train_Xscaled, train_Y)\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(5)\n",
    "\n",
    "clf.fit(X_train_fs, train_Y)\n",
    "X_test_fs = fs.transform(test_Xscaled)\n",
    "predictions = clf.predict(X_test_fs)\n",
    "\n",
    "accuracy = getAccuracy(test_Y, predictions)\n",
    "print('Accuracy: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens to accuracy if we change the ratio between training and test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers to the Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** <br> Assign a label to the test instance, basing on the following training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get K neighbours\n",
    "K = 1\n",
    "neighbours = getNeighbors(training_set, training_labels, testInstance, K)\n",
    "\n",
    "# get the label\n",
    "label = getResponse(neighbours['labels'])\n",
    "\n",
    "print (label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** <br> Can you scale the train_X feature set using the mean and standard deviation for train_X and this relation: \n",
    "\n",
    "$$ScaledX = \\frac{X - mean}{std}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute mean and standard deviation of training set\n",
    "mean = np.mean(train_X, axis=0)\n",
    "std = np.std(train_X, axis=0)\n",
    "\n",
    "# note that we scale test set using the mean and std of the training set\n",
    "train_Xscaled = (train_X-mean)/std\n",
    "test_Xscaled = (test_X-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
